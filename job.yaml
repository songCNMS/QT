description: DT with description regularization

environment:
  image: amlt-sing/pytorch-1.8.0-cuda11.1-cudnn8-devel
  setup:
    - sudo apt-get update --yes
    - sudo apt-get install --yes libosmesa6-dev libgl1-mesa-glx libglfw3 libgl1-mesa-dev
    # - apt-get install libgcrypt20 libgcrypt20-dev
    - sudo apt-get update -q \
      && DEBIAN_FRONTEND=noninteractive apt-get install -y \
      curl \
      git \
      libgl1-mesa-dev \
      libgl1-mesa-glx \
      libglew-dev \
      libosmesa6-dev \
      software-properties-common \
      net-tools \
      vim \
      virtualenv \
      wget \
      xpra \
      xserver-xorg-dev \
      && apt-get clean \
      && rm -rf /var/lib/apt/lists/*
    - alias python='python3.8'
    - conda update -n base -c defaults conda
    - conda install -c menpo osmesa --yes
    - pip install azureml-mlflow tensorboard --user
    # - cp -R .mujoco /root
    - cp -R .mujoco /home/aiscuser/
    - pip install -r requirements.txt
    - pip install git+https://github.com/Farama-Foundation/d4rl@master#egg=d4rl
    - export LD_LIBRARY_PATH=/home/aiscuser/.mujoco/mujoco210/bin
    - export LD_LIBRARY_PATH=/usr/local/nvidia/lib64:$LD_LIBRARY_PATH
    # - pip install -U torch
    - pip install numpy==1.21.6
    
target:
  service: sing
  name: msrresrchvc
  workspace_name: rag-workspace-eastus

data:
  local_dir: ./
  remote_dir: data/

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: $CONFIG_DIR/

# list of jobs to run, we run 2 jobs in this example
jobs:
- name: high_lr
  sku: G1
  identity: managed
  submit_args:
    env:
      _AZUREML_SINGULARITY_JOB_UAI: "/subscriptions/e033d461-1923-44a7-872b-78f1d35a86dd/resourcegroups/RAG-WUS/providers/Microsoft.ManagedIdentity/userAssignedIdentities/rag-workspace-eastus-mi"
  command:
    - export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/aiscuser/.mujoco/mujoco210/bin; python experiment.py --seed 123 --env citylearn --dataset medium-expert --eta 2.0 --grad_norm 5.0 --exp_name qt --save_path ./save/ --max_iters 100 --num_steps_per_iter 10000 --lr_decay --early_stop --k_rewards --use_discount --reprogram --desc_reg --eta3 10.0


# search:
#   job_template:
#     # you may use {random_string:s} to avoid job name collisions
#     # {auto:3s} generates lr_0.00000_mom_0.5, .. etc
#     # {auto:2s} generates lr_0.00000_mo_0.5, .. etc
#     name: "{experiment_name:s}_{auto:4s}"
#     sku: G1
#     command:
#     - export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/aiscuser/.mujoco/mujoco210/bin; python experiment.py --seed 123 --env citylearn --dataset medium-expert --eta {eta} --grad_norm {grad_norm} --exp_name qt --save_path ./save/ --max_iters 500 --num_steps_per_iter 10000 --lr_decay --early_stop --k_rewards --use_discount --reprogram --desc_reg --eta3 {eta3}
#   type: hyperdrive  # hyperparameter search type: hyperdrive, random, grid.  Default: hyperdrive
#   sampling: grid  # how to explore the hyperparameter space: random, grid or bayesian. Default: bayesian
#   max_trials: 256
#   parallel_trials: 16  # number of trials to run in parallel. Default: equals to max_trials.
#   params:
#     - name: eta
#       values: [0.01, 0.1, 1.0, 2.0, 4.0, 10.0, 20.0, 50.0]  # or equivalently choice(0.5, 0.9, 0.99)
#     - name: grad_norm
#       # spec: hyperdrive  # the default value
#       values: [1.0, 2.0, 4.0, 10.0]
#     - name: eta3
#       # spec: hyperdrive  # the default value
#       values: [0.01, 0.1, 1.0, 2.0, 4.0, 10.0, 20.0, 50.0]